{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "### IBM AutoAI-SDK Auto-Generated Notebook v1.12.2\n\n**Note:** Notebook code generated using AutoAI will execute successfully. If code is modified or reordered,   \nthere is no guarantee it will successfully execute. This pipeline is optimized for the original dataset.  \nThe pipeline may fail or produce sub-optimium results if used with different data. For different data,  \nplease consider returning to AutoAI Experiments to generate a new pipeline. Please read our documentation   \nfor more information:   \n<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-notebook.html\">Cloud Platform</a>  \n\n\nBefore modifying the pipeline or trying to re-fit the pipeline, consider:   \nThe notebook converts dataframes to numpy arrays before fitting the pipeline   \n(a current restriction of the preprocessor pipeline). The known_values_list is passed by reference   \nand populated with categorical values during fit of the preprocessing pipeline. Delete its members before re-fitting."}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"content\"></a>\n## Notebook content\n\nThis notebook contains steps and code to demonstrate AutoAI pipeline. This notebook introduces commands for getting data,  \npipeline model, model inspection and testing.\n\nSome familiarity with Python is helpful. This notebook uses Python 3."}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "## Notebook goals\n\n-  inspection of trained pipeline via graphical vizualization and source code preview.\n-  pipeline evaluation.\n-  pipeline deployment and webservice scoring\n\n## Contents\n\nThis notebook contains the following parts:\n\n1.\t[Setup](#setup)         \n    a.  [AutoAI experiment metadata](#variables_definition)      \n2.\t[Pipeline inspection](#inspection)      \n    a.  [Get historical optimizer instance](#get_hist_and_train)      \n    b.  [Get pipeline model](#get_pipeline)      \n    c.  [Preview pipeline model as python code](#preview_model_to_python_code)      \n    d.  [Visualize pipeline model](#visualize_pipeline)      \n    e.  [Read training and holdout data](#train_holdout_read)        \n    f.  [Test pipeline model locally](#test_model)       \n3.\t[Pipeline refinery](#refinery)       \n    a.  [Pipeline definition source code](#pipeline_definition)      \n    b.  [Lale library](#lale_library)      \n4.\t[Deploy and score](#scoring)       \n    a.  [Insert WML credentials](#wml_credentials)   \n    b.  [Create deployment](#deployment)      \n    c.  [Score webservice](#online_scoring)        \n    d.  [Delete deployment](#delete_deployment)       \n5.  [Authors](#authors)      "}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"setup\"></a>\n# Setup\n\nBefore you use the sample code in this notebook, you must perform the following setup tasks:\n - `watson-machine-learning-client` uninstallation of the old client\n - `watson-machine-learning-client-V4` installation\n - `autoai-libs` installation/upgrade\n - `lightgbm` or `xgboost` installation/downgrade if they are needed"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "!pip uninstall watson-machine-learning-client -y", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Uninstalling watson-machine-learning-client-1.0.376:\n  Successfully uninstalled watson-machine-learning-client-1.0.376\n", "name": "stdout"}]}, {"metadata": {"pycharm": {"is_executing": false, "name": "#%%\n"}}, "cell_type": "code", "source": "!pip install -U watson-machine-learning-client-V4", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "Collecting watson-machine-learning-client-V4\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/9a/cd255fb8e3a67a688c36748233eb57ac4a4331fa574ef678c3cd69e14e44/watson_machine_learning_client_V4-1.0.99-py3-none-any.whl (1.2MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.2MB 8.7MB/s eta 0:00:01\n\u001b[?25hCollecting ibm-cos-sdk==2.6.0 (from watson-machine-learning-client-V4)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/91/86b2816c7b77d816b03a1ad6cf7db4b1f67556af395d5b93fdae6086c933/ibm-cos-sdk-2.6.0.tar.gz (53kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 61kB 30.8MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: lomond in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (0.3.3)\nRequirement already satisfied, skipping upgrade: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (2.21.0)\nRequirement already satisfied, skipping upgrade: pandas<=0.25.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (0.24.1)\nRequirement already satisfied, skipping upgrade: tabulate in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (0.8.2)\nRequirement already satisfied, skipping upgrade: urllib3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (1.24.1)\nRequirement already satisfied, skipping upgrade: certifi in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (2020.4.5.1)\nCollecting ibm-cos-sdk-core==2.6.0 (from ibm-cos-sdk==2.6.0->watson-machine-learning-client-V4)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/c1/c823507c472bf88dbd045445df6850744111d34fd218c6ea3b9c9bde2cfe/ibm-cos-sdk-core-2.6.0.tar.gz (763kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 768kB 40.8MB/s eta 0:00:01\n\u001b[?25hCollecting ibm-cos-sdk-s3transfer==2.6.0 (from ibm-cos-sdk==2.6.0->watson-machine-learning-client-V4)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/92/682a28b99777a3fdc65e6d5641ed7e1ca470d0eab3bb2826cc30c6b60e21/ibm-cos-sdk-s3transfer-2.6.0.tar.gz (221kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 225kB 52.0MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk==2.6.0->watson-machine-learning-client-V4) (0.9.3)\nRequirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lomond->watson-machine-learning-client-V4) (1.12.0)\nRequirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->watson-machine-learning-client-V4) (2.8)\nRequirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->watson-machine-learning-client-V4) (3.0.4)\nRequirement already satisfied, skipping upgrade: pytz>=2011k in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas<=0.25.3->watson-machine-learning-client-V4) (2018.9)\nRequirement already satisfied, skipping upgrade: numpy>=1.12.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas<=0.25.3->watson-machine-learning-client-V4) (1.15.4)\nRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas<=0.25.3->watson-machine-learning-client-V4) (2.7.5)\nRequirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk-core==2.6.0->ibm-cos-sdk==2.6.0->watson-machine-learning-client-V4) (0.14)\nBuilding wheels for collected packages: ibm-cos-sdk, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer\n  Building wheel for ibm-cos-sdk (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/37/9c/c4/a2c610ccb877d37c2cb87a5bfe55845fecffd6bb01bcd5e9d5\n  Building wheel for ibm-cos-sdk-core (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/75/93/e6/23071b2c037147a0993d34b64a03e51abca84435fc9cd6a278\n  Building wheel for ibm-cos-sdk-s3transfer (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/23/d9/d7/43fd95b014eed89466154d8373bf4cffbb3d972de7841e213c\nSuccessfully built ibm-cos-sdk ibm-cos-sdk-core ibm-cos-sdk-s3transfer\nInstalling collected packages: ibm-cos-sdk-core, ibm-cos-sdk-s3transfer, ibm-cos-sdk, watson-machine-learning-client-V4\n  Found existing installation: ibm-cos-sdk-core 2.4.3\n    Uninstalling ibm-cos-sdk-core-2.4.3:\n      Successfully uninstalled ibm-cos-sdk-core-2.4.3\n  Found existing installation: ibm-cos-sdk-s3transfer 2.4.3\n    Uninstalling ibm-cos-sdk-s3transfer-2.4.3:\n      Successfully uninstalled ibm-cos-sdk-s3transfer-2.4.3\n  Found existing installation: ibm-cos-sdk 2.4.3\n    Uninstalling ibm-cos-sdk-2.4.3:\n      Successfully uninstalled ibm-cos-sdk-2.4.3\nSuccessfully installed ibm-cos-sdk-2.6.0 ibm-cos-sdk-core-2.6.0 ibm-cos-sdk-s3transfer-2.6.0 watson-machine-learning-client-V4-1.0.99\n", "name": "stdout"}]}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "!pip install -U autoai-libs", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "Collecting autoai-libs\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/cb/4144b9ee74fcb058cea934478c87f2444cfa7b38a01396507f1a417030cb/autoai_libs-1.10.12-37-cp36-cp36m-manylinux1_x86_64.whl (4.3MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.3MB 8.4MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn==0.20.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from autoai-libs) (0.20.3)\nCollecting category-encoders==2.1.0 (from autoai-libs)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/52/c54191ad3782de633ea3d6ee3bb2837bda0cf3bc97644bb6375cf14150a0/category_encoders-2.1.0-py2.py3-none-any.whl (100kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 102kB 37.8MB/s ta 0:00:01\n\u001b[?25hCollecting numpy>=1.16.4 (from autoai-libs)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/a9/b1bc4c935ed063766bce7d3e8c7b20bd52e515ff1c732b02caacf7918e5a/numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20.1MB 34.7MB/s eta 0:00:01\n\u001b[?25hCollecting pandas<1.0.0,>=0.24.2 (from autoai-libs)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10.4MB 50.5MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.13.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn==0.20.3->autoai-libs) (1.2.0)\nRequirement already satisfied, skipping upgrade: patsy>=0.4.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from category-encoders==2.1.0->autoai-libs) (0.5.1)\nRequirement already satisfied, skipping upgrade: statsmodels>=0.6.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from category-encoders==2.1.0->autoai-libs) (0.9.0)\nRequirement already satisfied, skipping upgrade: pytz>=2017.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas<1.0.0,>=0.24.2->autoai-libs) (2018.9)\nRequirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas<1.0.0,>=0.24.2->autoai-libs) (2.7.5)\nRequirement already satisfied, skipping upgrade: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from patsy>=0.4.1->category-encoders==2.1.0->autoai-libs) (1.12.0)\n\u001b[31mERROR: tensorflow 1.13.1 requires tensorboard<1.14.0,>=1.13.0, which is not installed.\u001b[0m\nInstalling collected packages: numpy, pandas, category-encoders, autoai-libs\n  Found existing installation: numpy 1.15.4\n    Uninstalling numpy-1.15.4:\n      Successfully uninstalled numpy-1.15.4\n  Found existing installation: pandas 0.24.1\n    Uninstalling pandas-0.24.1:\n      Successfully uninstalled pandas-0.24.1\n  Found existing installation: category-encoders 2.0.0\n    Uninstalling category-encoders-2.0.0:\n      Successfully uninstalled category-encoders-2.0.0\n  Found existing installation: autoai-libs 1.10.5\n    Uninstalling autoai-libs-1.10.5:\n      Successfully uninstalled autoai-libs-1.10.5\nSuccessfully installed autoai-libs-1.10.12 category-encoders-2.1.0 numpy-1.18.5 pandas-0.25.3\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"variables_definition\"></a>\n### AutoAI experiment metadata\n\nThis cell contains input parameters provided to run the AutoAI experiment in Watson Studio and COS credentials required to retrieve AutoAI pipeline."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "from watson_machine_learning_client.helpers import DataConnection, S3Connection, S3Location\n\nexperiment_metadata = dict(\n   prediction_type='regression',\n   prediction_column='Life expectancy ',\n   test_size=0.1,\n   scoring='neg_root_mean_squared_error',\n   max_number_of_estimators=2,\n   training_data_reference = [DataConnection(\n        connection=S3Connection(\n            api_key='-FBirI_GeRd9KdPUc0TrSwWok_-zzYym1GfWrHLAl_Cm',\n            auth_endpoint='https://iam.bluemix.net/oidc/token/',\n            endpoint_url='https://s3.eu-geo.objectstorage.softlayer.net'\n        ),\n            location=S3Location(\n            bucket='lifeexpectancyprediction-donotdelete-pr-ixfxfbory8m9ve',\n            path='Life Expectancy Data.csv'\n        ))\n    ],\n    training_result_reference = DataConnection(\n        connection=S3Connection(\n            api_key='-FBirI_GeRd9KdPUc0TrSwWok_-zzYym1GfWrHLAl_Cm',\n            auth_endpoint='https://iam.bluemix.net/oidc/token/',\n            endpoint_url='https://s3.eu-geo.objectstorage.softlayer.net'\n        ),\n        location=S3Location(\n            bucket='lifeexpectancyprediction-donotdelete-pr-ixfxfbory8m9ve',\n            path='auto_ml/32194f60-49cc-4745-b783-abb607bd7919/wml_data/8232d1a5-f358-4133-8e65-1157257be9b0/data/automl',\n            model_location='auto_ml/32194f60-49cc-4745-b783-abb607bd7919/wml_data/8232d1a5-f358-4133-8e65-1157257be9b0/data/automl/cognito_output/Pipeline1/model.pickle',\n            training_status='auto_ml/32194f60-49cc-4745-b783-abb607bd7919/wml_data/8232d1a5-f358-4133-8e65-1157257be9b0/training-status.json'\n        )\n    ))\n\npipeline_name='Pipeline_3'", "execution_count": 4, "outputs": []}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"inspection\"></a>\n## Pipeline inspection\nIn this section you will get the trained pipeline model from the AutoAI experiment and inspect it.  \nYou will see pipeline as a pythone code, graphically visualized and at the end, you will perform a local test.\n"}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"get_hist_and_train\"></a>\n### Get historical optimizer instance\n\nThe next cell contains code for retrieving fitted optimizer."}, {"metadata": {"pycharm": {"is_executing": false, "name": "#%%\n"}}, "cell_type": "code", "source": "from watson_machine_learning_client.experiment import AutoAI\n\noptimizer = AutoAI().runs.get_optimizer(metadata=experiment_metadata)", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "Warning: To use AutoAI with xgboost estimators, you need to have xgboost 0.90 installed.\nWarning: To use AutoAI with lightgbm estimators, you need to have lightgbm 2.2.3 installed.\n", "name": "stdout"}]}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"get_pipeline\"></a>\n### Get pipeline model\n\nThe following cell loads selected AutoAI pipeline model. If you want to get pure scikit-learn pipeline specify `as_type='sklearn'` parameter. By default enriched scikit-learn pipeline is returned `as_type='lale'`."}, {"metadata": {"pycharm": {"is_executing": false, "name": "#%%\n"}}, "cell_type": "code", "source": "pipeline_model = optimizer.get_pipeline(pipeline_name=pipeline_name)", "execution_count": 6, "outputs": []}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"preview_model_to_python_code\"></a>\n### Preview pipeline model as python code\nIn the next cell, downloaded pipeline model could be previewed as a python code.  \nYou will be able to see what exact steps are involved in model creation."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "pipeline_model.pretty_print(combinators=False, ipython_display=True)", "execution_count": 7, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.Markdown object>", "text/markdown": "```python\nfrom autoai_libs.transformers.exportable import ColumnSelector\nfrom lale.lib.autoai_libs import NumpyColumnSelector\nfrom lale.lib.autoai_libs import CompressStrings\nfrom lale.lib.autoai_libs import NumpyReplaceMissingValues\nfrom lale.lib.autoai_libs import NumpyReplaceUnknownValues\nfrom lale.lib.autoai_libs import boolean2float\nfrom lale.lib.autoai_libs import CatImputer\nfrom lale.lib.autoai_libs import CatEncoder\nimport numpy as np\nfrom lale.lib.autoai_libs import float32_transform\nfrom lale.operators import make_pipeline\nfrom lale.lib.autoai_libs import FloatStr2Float\nfrom lale.lib.autoai_libs import NumImputer\nfrom lale.lib.autoai_libs import OptStandardScaler\nfrom lale.operators import make_union\nfrom lale.lib.autoai_libs import NumpyPermuteArray\nfrom lale.lib.autoai_libs import TA1\nimport autoai_libs.utils.fc_methods\nfrom lale.lib.autoai_libs import FS1\nimport autoai_libs.cognito.transforms.textras_methods\nfrom lale.lib.sklearn import ExtraTreesRegressor\n\ncolumn_selector = ColumnSelector(columns_indices_list=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\nnumpy_column_selector_0 = NumpyColumnSelector(columns=[0, 1, 6, 10, 12])\ncompress_strings = CompressStrings(compress_type='hash', dtypes_list=['int_num', 'char_str', 'float_int_num', 'float_int_num', 'float_int_num'], missing_values_reference_list=['', '-', '?', float('nan')], misslist_list=[[], [], [float('nan')], [float('nan')], [float('nan')]])\nnumpy_replace_missing_values_0 = NumpyReplaceMissingValues(filling_values=float('nan'), missing_values=[float('nan')])\nnumpy_replace_unknown_values = NumpyReplaceUnknownValues(filling_values=float('nan'), filling_values_list=[float('nan'), float('nan'), 100001, 100001, 100001], known_values_list=[[2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015], [316899882848231090403546313428573395088, 26986457628094788534232875252534333277], [1.0, 2.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 11.0, 14.0, 15.0, 17.0, 18.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 31.0, 32.0, 33.0, 35.0, 36.0, 37.0, 38.0, 39.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0], [3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 23.0, 24.0, 26.0, 31.0, 32.0, 33.0, 35.0, 36.0, 37.0, 38.0, 39.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0], [2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 19.0, 21.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0]], missing_values_reference_list=['', '-', '?', float('nan')])\ncat_imputer = CatImputer(missing_values=float('nan'), sklearn_version_family='20', strategy='most_frequent')\ncat_encoder = CatEncoder(dtype=np.float64, handle_unknown='error', sklearn_version_family='20')\npipeline_0 = make_pipeline(numpy_column_selector_0, compress_strings, numpy_replace_missing_values_0, numpy_replace_unknown_values, boolean2float(), cat_imputer, cat_encoder, float32_transform())\nnumpy_column_selector_1 = NumpyColumnSelector(columns=[2, 3, 4, 5, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19])\nfloat_str2_float = FloatStr2Float(dtypes_list=['float_int_num', 'int_num', 'float_num', 'float_num', 'int_num', 'float_num', 'int_num', 'float_num', 'float_num', 'float_num', 'float_num', 'float_num', 'float_num', 'float_num', 'float_num'], missing_values_reference_list=[float('nan')])\nnumpy_replace_missing_values_1 = NumpyReplaceMissingValues(filling_values=float('nan'), missing_values=[float('nan')])\nnum_imputer = NumImputer(missing_values=float('nan'), strategy='median')\nopt_standard_scaler = OptStandardScaler(num_scaler_copy=None, num_scaler_with_mean=None, num_scaler_with_std=None, use_scaler_flag=False)\npipeline_1 = make_pipeline(numpy_column_selector_1, float_str2_float, numpy_replace_missing_values_1, num_imputer, opt_standard_scaler, float32_transform())\nunion = make_union(pipeline_0, pipeline_1)\nnumpy_permute_array = NumpyPermuteArray(axis=0, permutation_indices=[0, 1, 6, 10, 12, 2, 3, 4, 5, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19])\nta1_0 = TA1(fun=np.sqrt, name='sqrt', datatypes=['numeric'], feat_constraints=[autoai_libs.utils.fc_methods.is_non_negative, autoai_libs.utils.fc_methods.is_not_categorical], col_names=['Year', 'Status', 'Adult Mortality', 'infant deaths', 'Alcohol', 'percentage expenditure', 'Hepatitis B', 'Measles ', ' BMI ', 'under-five deaths ', 'Polio', 'Total expenditure', 'Diphtheria ', ' HIV/AIDS', 'GDP', 'Population', ' thinness  1-19 years', ' thinness 5-9 years', 'Income composition of resources', 'Schooling'], col_dtypes=[np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32')])\nfs1_0 = FS1(cols_ids_must_keep=range(0, 20), additional_col_count_to_keep=20, ptype='regression')\nta1_1 = TA1(fun=autoai_libs.cognito.transforms.textras_methods.sigmoid, name='sigmoid', datatypes=['numeric'], feat_constraints=[autoai_libs.utils.fc_methods.is_not_categorical], col_names=['Year', 'Status', 'Adult Mortality', 'infant deaths', 'Alcohol', 'percentage expenditure', 'Hepatitis B', 'Measles ', ' BMI ', 'under-five deaths ', 'Polio', 'Total expenditure', 'Diphtheria ', ' HIV/AIDS', 'GDP', 'Population', ' thinness  1-19 years', ' thinness 5-9 years', 'Income composition of resources', 'Schooling', 'sqrt(Adult Mortality)', 'sqrt(infant deaths)', 'sqrt(Alcohol)', 'sqrt(percentage expenditure)', 'sqrt(Hepatitis B)', 'sqrt(Measles )', 'sqrt( BMI )', 'sqrt(under-five deaths )', 'sqrt(Polio)', 'sqrt(Total expenditure)', 'sqrt(Diphtheria )', 'sqrt( HIV/AIDS)', 'sqrt(GDP)', 'sqrt(Population)', 'sqrt( thinness  1-19 years)', 'sqrt( thinness 5-9 years)', 'sqrt(Income composition of resources)', 'sqrt(Schooling)'], col_dtypes=[np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32')])\nfs1_1 = FS1(cols_ids_must_keep=range(0, 20), additional_col_count_to_keep=20, ptype='regression')\nextra_trees_regressor = ExtraTreesRegressor(bootstrap=True, n_jobs=2, oob_score=True, random_state=33)\npipeline = make_pipeline(column_selector, union, numpy_permute_array, ta1_0, fs1_0, ta1_1, fs1_1, extra_trees_regressor)\n```"}, "metadata": {}}]}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"visualize_pipeline\"></a>\n### Visualize pipeline model\n\nPreview pipeline model stages as graph. Each node's name links to detailed description of the stage.\n"}, {"metadata": {"pycharm": {"is_executing": false, "name": "#%%\n"}}, "cell_type": "code", "source": "pipeline_model.visualize()", "execution_count": 8, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<graphviz.dot.Digraph at 0x7fc19c59e8d0>", "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: cluster:(root) Pages: 1 -->\n<svg width=\"1817pt\" height=\"163pt\"\n viewBox=\"0.00 0.00 1817.43 162.54\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 158.5391)\">\n<title>cluster:(root)</title>\n<g id=\"a_graph0\"><a xlink:title=\"(root) = ...\">\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-158.5391 1813.4255,-158.5391 1813.4255,4 -4,4\"/>\n</a>\n</g>\n<!-- column_selector -->\n<g id=\"node1\" class=\"node\">\n<title>column_selector</title>\n<g id=\"a_node1\"><a xlink:title=\"column_selector = ColumnSelector(columns_indices_list=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"39.598\" cy=\"-75.7696\" rx=\"39.6962\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"39.598\" y=\"-78.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Column&#45;</text>\n<text text-anchor=\"middle\" x=\"39.598\" y=\"-66.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Selector</text>\n</a>\n</g>\n</g>\n<!-- numpy_column_selector_0 -->\n<g id=\"node2\" class=\"node\">\n<title>numpy_column_selector_0</title>\n<g id=\"a_node2\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_column_selector.html\" xlink:title=\"numpy_column_selector_0 = NumpyColumnSelector(columns=[0, 1, 6, 10, 12])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"154.7939\" cy=\"-99.7696\" rx=\"39.6962\" ry=\"28.0702\"/>\n<text text-anchor=\"middle\" x=\"154.7939\" y=\"-108.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"154.7939\" y=\"-96.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Column&#45;</text>\n<text text-anchor=\"middle\" x=\"154.7939\" y=\"-84.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Selector</text>\n</a>\n</g>\n</g>\n<!-- column_selector&#45;&gt;numpy_column_selector_0 -->\n<g id=\"edge1\" class=\"edge\">\n<title>column_selector&#45;&gt;numpy_column_selector_0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M76.3634,-83.4293C85.9439,-85.4253 96.4132,-87.6065 106.4923,-89.7064\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"105.8904,-93.156 116.3941,-91.7693 107.3182,-86.3032 105.8904,-93.156\"/>\n</g>\n<!-- numpy_column_selector_1 -->\n<g id=\"node10\" class=\"node\">\n<title>numpy_column_selector_1</title>\n<g id=\"a_node10\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_column_selector.html\" xlink:title=\"numpy_column_selector_1 = NumpyColumnSelector(columns=[2, 3, 4, 5, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"279.1823\" cy=\"-48.7696\" rx=\"39.6962\" ry=\"28.0702\"/>\n<text text-anchor=\"middle\" x=\"279.1823\" y=\"-57.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"279.1823\" y=\"-45.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Column&#45;</text>\n<text text-anchor=\"middle\" x=\"279.1823\" y=\"-33.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Selector</text>\n</a>\n</g>\n</g>\n<!-- column_selector&#45;&gt;numpy_column_selector_1 -->\n<g id=\"edge9\" class=\"edge\">\n<title>column_selector&#45;&gt;numpy_column_selector_1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M78.3576,-71.4015C119.5177,-66.763 184.7053,-59.4167 229.5843,-54.359\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"230.1361,-57.8191 239.6812,-53.2211 229.3521,-50.8631 230.1361,-57.8191\"/>\n</g>\n<!-- compress_strings -->\n<g id=\"node3\" class=\"node\">\n<title>compress_strings</title>\n<g id=\"a_node3\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.compress_strings.html\" xlink:title=\"compress_strings = CompressStrings(compress_type=&#39;hash&#39;, dtypes_list=[&#39;int_num&#39;, &#39;char_str&#39;, &#39;float_int_num&#39;, &#39;float_int_num&#39;, &#39;float_int_num&#39;], missing_values_reference_list=[&#39;&#39;, &#39;&#45;&#39;, &#39;?&#39;, float(&#39;nan&#39;)], misslist_list=[[], [], [float(&#39;nan&#39;)], [float(&#39;nan&#39;)], [float(&#39;nan&#39;)]])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"279.1823\" cy=\"-108.7696\" rx=\"48.5816\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"279.1823\" y=\"-111.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Compress&#45;</text>\n<text text-anchor=\"middle\" x=\"279.1823\" y=\"-99.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Strings</text>\n</a>\n</g>\n</g>\n<!-- numpy_column_selector_0&#45;&gt;compress_strings -->\n<g id=\"edge2\" class=\"edge\">\n<title>numpy_column_selector_0&#45;&gt;compress_strings</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M194.4932,-102.642C202.7719,-103.241 211.6651,-103.8844 220.4653,-104.5211\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"220.4841,-108.0316 230.7107,-105.2624 220.9893,-101.0498 220.4841,-108.0316\"/>\n</g>\n<!-- numpy_replace_missing_values_0 -->\n<g id=\"node4\" class=\"node\">\n<title>numpy_replace_missing_values_0</title>\n<g id=\"a_node4\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_replace_missing_values.html\" xlink:title=\"numpy_replace_missing_values_0 = NumpyReplaceMissingValues(filling_values=float(&#39;nan&#39;), missing_values=[float(&#39;nan&#39;)])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"403.5706\" cy=\"-114.7696\" rx=\"39.6962\" ry=\"36.5405\"/>\n<text text-anchor=\"middle\" x=\"403.5706\" y=\"-129.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"403.5706\" y=\"-117.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Replace&#45;</text>\n<text text-anchor=\"middle\" x=\"403.5706\" y=\"-105.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Missing&#45;</text>\n<text text-anchor=\"middle\" x=\"403.5706\" y=\"-93.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Values</text>\n</a>\n</g>\n</g>\n<!-- compress_strings&#45;&gt;numpy_replace_missing_values_0 -->\n<g id=\"edge3\" class=\"edge\">\n<title>compress_strings&#45;&gt;numpy_replace_missing_values_0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M327.9868,-111.1237C336.4064,-111.5298 345.1697,-111.9525 353.619,-112.3601\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"353.5685,-115.8616 363.7256,-112.8476 353.9058,-108.8698 353.5685,-115.8616\"/>\n</g>\n<!-- numpy_replace_unknown_values -->\n<g id=\"node5\" class=\"node\">\n<title>numpy_replace_unknown_values</title>\n<g id=\"a_node5\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_replace_unknown_values.html\" xlink:title=\"numpy_replace_unknown_values = NumpyReplaceUnknownValues(filling_values=float(&#39;nan&#39;), filling_values_list=[float(&#39;nan&#39;), float(&#39;nan&#39;), 100001, 100001, 100001], known_values_list=[[2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015], [3168998828482310904035463134285...)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"525.8377\" cy=\"-117.7696\" rx=\"46.8387\" ry=\"36.5405\"/>\n<text text-anchor=\"middle\" x=\"525.8377\" y=\"-132.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"525.8377\" y=\"-120.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Replace&#45;</text>\n<text text-anchor=\"middle\" x=\"525.8377\" y=\"-108.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Unknown&#45;</text>\n<text text-anchor=\"middle\" x=\"525.8377\" y=\"-96.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Values</text>\n</a>\n</g>\n</g>\n<!-- numpy_replace_missing_values_0&#45;&gt;numpy_replace_unknown_values -->\n<g id=\"edge4\" class=\"edge\">\n<title>numpy_replace_missing_values_0&#45;&gt;numpy_replace_unknown_values</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M443.2672,-115.7436C451.4865,-115.9452 460.2978,-116.1614 468.9927,-116.3748\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"469.0212,-119.8764 479.104,-116.6229 469.1929,-112.8785 469.0212,-119.8764\"/>\n</g>\n<!-- boolean2float -->\n<g id=\"node6\" class=\"node\">\n<title>boolean2float</title>\n<g id=\"a_node6\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.boolean2float.html\" xlink:title=\"boolean2float = boolean2float()\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"656.5082\" cy=\"-115.7696\" rx=\"48.0029\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"656.5082\" y=\"-112.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">boolean2float</text>\n</a>\n</g>\n</g>\n<!-- numpy_replace_unknown_values&#45;&gt;boolean2float -->\n<g id=\"edge5\" class=\"edge\">\n<title>numpy_replace_unknown_values&#45;&gt;boolean2float</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M572.6436,-117.0532C580.8696,-116.9273 589.5227,-116.7948 598.0197,-116.6648\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"598.3222,-120.1606 608.2675,-116.5079 598.215,-113.1615 598.3222,-120.1606\"/>\n</g>\n<!-- cat_imputer -->\n<g id=\"node7\" class=\"node\">\n<title>cat_imputer</title>\n<g id=\"a_node7\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.cat_imputer.html\" xlink:title=\"cat_imputer = CatImputer(missing_values=float(&#39;nan&#39;), sklearn_version_family=&#39;20&#39;, strategy=&#39;most_frequent&#39;)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"786.4715\" cy=\"-113.7696\" rx=\"38.3684\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"786.4715\" y=\"-116.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Cat&#45;</text>\n<text text-anchor=\"middle\" x=\"786.4715\" y=\"-104.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Imputer</text>\n</a>\n</g>\n</g>\n<!-- boolean2float&#45;&gt;cat_imputer -->\n<g id=\"edge6\" class=\"edge\">\n<title>boolean2float&#45;&gt;cat_imputer</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M704.5325,-115.0305C715.3821,-114.8635 726.9098,-114.6861 737.7863,-114.5188\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"738.0265,-118.0156 747.9715,-114.362 737.9187,-111.0164 738.0265,-118.0156\"/>\n</g>\n<!-- cat_encoder -->\n<g id=\"node8\" class=\"node\">\n<title>cat_encoder</title>\n<g id=\"a_node8\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.cat_encoder.html\" xlink:title=\"cat_encoder = CatEncoder(dtype=np.float64, handle_unknown=&#39;error&#39;, sklearn_version_family=&#39;20&#39;)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"913.6883\" cy=\"-108.7696\" rx=\"38.3684\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"913.6883\" y=\"-111.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Cat&#45;</text>\n<text text-anchor=\"middle\" x=\"913.6883\" y=\"-99.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Encoder</text>\n</a>\n</g>\n</g>\n<!-- cat_imputer&#45;&gt;cat_encoder -->\n<g id=\"edge7\" class=\"edge\">\n<title>cat_imputer&#45;&gt;cat_encoder</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M824.6408,-112.2694C837.4716,-111.7651 851.9559,-111.1958 865.457,-110.6652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"865.6912,-114.1588 875.546,-110.2687 865.4162,-107.1642 865.6912,-114.1588\"/>\n</g>\n<!-- float32_transform_0 -->\n<g id=\"node9\" class=\"node\">\n<title>float32_transform_0</title>\n<g id=\"a_node9\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.float32_transform.html\" xlink:title=\"float32_transform_0 = float32_transform()\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1040.198\" cy=\"-102.7696\" rx=\"45.011\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"1040.198\" y=\"-105.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">float32_&#45;</text>\n<text text-anchor=\"middle\" x=\"1040.198\" y=\"-93.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">transform</text>\n</a>\n</g>\n</g>\n<!-- cat_encoder&#45;&gt;float32_transform_0 -->\n<g id=\"edge8\" class=\"edge\">\n<title>cat_encoder&#45;&gt;float32_transform_0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M951.9887,-106.9531C962.3452,-106.4619 973.7645,-105.9203 984.8542,-105.3944\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"985.0832,-108.8875 994.9061,-104.9176 984.7515,-101.8954 985.0832,-108.8875\"/>\n</g>\n<!-- concat_features -->\n<g id=\"node16\" class=\"node\">\n<title>concat_features</title>\n<g id=\"a_node16\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lale.concat_features.html\" xlink:title=\"concat_features = ConcatFeatures()\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1161.7579\" cy=\"-82.7696\" rx=\"40.1111\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"1161.7579\" y=\"-85.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Concat&#45;</text>\n<text text-anchor=\"middle\" x=\"1161.7579\" y=\"-73.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Features</text>\n</a>\n</g>\n</g>\n<!-- float32_transform_0&#45;&gt;concat_features -->\n<g id=\"edge15\" class=\"edge\">\n<title>float32_transform_0&#45;&gt;concat_features</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1082.7137,-95.7745C1092.6755,-94.1355 1103.3588,-92.3778 1113.5492,-90.7012\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1114.2311,-94.1362 1123.5302,-89.0591 1113.0946,-87.229 1114.2311,-94.1362\"/>\n</g>\n<!-- float_str2_float -->\n<g id=\"node11\" class=\"node\">\n<title>float_str2_float</title>\n<g id=\"a_node11\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.float_str2_float.html\" xlink:title=\"float_str2_float = FloatStr2Float(dtypes_list=[&#39;float_int_num&#39;, &#39;int_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;, &#39;int_num&#39;, &#39;float_num&#39;, &#39;int_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;], missing_values_reference_list=[float(&#39;nan&#39;)])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"403.5706\" cy=\"-40.7696\" rx=\"28.0702\" ry=\"28.0702\"/>\n<text text-anchor=\"middle\" x=\"403.5706\" y=\"-49.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Float&#45;</text>\n<text text-anchor=\"middle\" x=\"403.5706\" y=\"-37.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Str2&#45;</text>\n<text text-anchor=\"middle\" x=\"403.5706\" y=\"-25.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Float</text>\n</a>\n</g>\n</g>\n<!-- numpy_column_selector_1&#45;&gt;float_str2_float -->\n<g id=\"edge10\" class=\"edge\">\n<title>numpy_column_selector_1&#45;&gt;float_str2_float</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M318.8815,-46.2163C333.6425,-45.267 350.3573,-44.192 365.0144,-43.2493\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"365.5113,-46.7247 375.266,-42.59 365.0619,-39.7391 365.5113,-46.7247\"/>\n</g>\n<!-- numpy_replace_missing_values_1 -->\n<g id=\"node12\" class=\"node\">\n<title>numpy_replace_missing_values_1</title>\n<g id=\"a_node12\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_replace_missing_values.html\" xlink:title=\"numpy_replace_missing_values_1 = NumpyReplaceMissingValues(filling_values=float(&#39;nan&#39;), missing_values=[float(&#39;nan&#39;)])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"525.8377\" cy=\"-36.7696\" rx=\"39.6962\" ry=\"36.5405\"/>\n<text text-anchor=\"middle\" x=\"525.8377\" y=\"-51.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"525.8377\" y=\"-39.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Replace&#45;</text>\n<text text-anchor=\"middle\" x=\"525.8377\" y=\"-27.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Missing&#45;</text>\n<text text-anchor=\"middle\" x=\"525.8377\" y=\"-15.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Values</text>\n</a>\n</g>\n</g>\n<!-- float_str2_float&#45;&gt;numpy_replace_missing_values_1 -->\n<g id=\"edge11\" class=\"edge\">\n<title>float_str2_float&#45;&gt;numpy_replace_missing_values_1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M431.9285,-39.8418C444.9969,-39.4143 460.9023,-38.8939 475.881,-38.4039\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"476.1764,-41.8962 486.0566,-38.071 475.9474,-34.8999 476.1764,-41.8962\"/>\n</g>\n<!-- num_imputer -->\n<g id=\"node13\" class=\"node\">\n<title>num_imputer</title>\n<g id=\"a_node13\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.num_imputer.html\" xlink:title=\"num_imputer = NumImputer(missing_values=float(&#39;nan&#39;), strategy=&#39;median&#39;)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"656.5082\" cy=\"-49.7696\" rx=\"38.3684\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"656.5082\" y=\"-52.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Num&#45;</text>\n<text text-anchor=\"middle\" x=\"656.5082\" y=\"-40.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Imputer</text>\n</a>\n</g>\n</g>\n<!-- numpy_replace_missing_values_1&#45;&gt;num_imputer -->\n<g id=\"edge12\" class=\"edge\">\n<title>numpy_replace_missing_values_1&#45;&gt;num_imputer</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M565.3977,-40.7053C579.0584,-42.0643 594.5094,-43.6015 608.7555,-45.0188\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"608.5757,-48.5181 618.8731,-46.0254 609.2687,-41.5525 608.5757,-48.5181\"/>\n</g>\n<!-- opt_standard_scaler -->\n<g id=\"node14\" class=\"node\">\n<title>opt_standard_scaler</title>\n<g id=\"a_node14\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.opt_standard_scaler.html\" xlink:title=\"opt_standard_scaler = OptStandardScaler(num_scaler_copy=None, num_scaler_with_mean=None, num_scaler_with_std=None, use_scaler_flag=False)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"786.4715\" cy=\"-55.7696\" rx=\"45.9239\" ry=\"28.0702\"/>\n<text text-anchor=\"middle\" x=\"786.4715\" y=\"-64.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Opt&#45;</text>\n<text text-anchor=\"middle\" x=\"786.4715\" y=\"-52.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Standard&#45;</text>\n<text text-anchor=\"middle\" x=\"786.4715\" y=\"-40.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Scaler</text>\n</a>\n</g>\n</g>\n<!-- num_imputer&#45;&gt;opt_standard_scaler -->\n<g id=\"edge13\" class=\"edge\">\n<title>num_imputer&#45;&gt;opt_standard_scaler</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M694.7985,-51.5373C705.8016,-52.0453 718.0405,-52.6103 729.8994,-53.1578\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"730.0315,-56.6675 740.1823,-53.6325 730.3544,-49.675 730.0315,-56.6675\"/>\n</g>\n<!-- float32_transform_1 -->\n<g id=\"node15\" class=\"node\">\n<title>float32_transform_1</title>\n<g id=\"a_node15\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.float32_transform.html\" xlink:title=\"float32_transform_1 = float32_transform()\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"913.6883\" cy=\"-59.7696\" rx=\"45.011\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"913.6883\" y=\"-62.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">float32_&#45;</text>\n<text text-anchor=\"middle\" x=\"913.6883\" y=\"-50.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">transform</text>\n</a>\n</g>\n</g>\n<!-- opt_standard_scaler&#45;&gt;float32_transform_1 -->\n<g id=\"edge14\" class=\"edge\">\n<title>opt_standard_scaler&#45;&gt;float32_transform_1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M832.3997,-57.2136C840.789,-57.4774 849.6241,-57.7552 858.2549,-58.0266\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"858.149,-61.5249 868.2541,-58.341 858.369,-54.5284 858.149,-61.5249\"/>\n</g>\n<!-- float32_transform_1&#45;&gt;concat_features -->\n<g id=\"edge16\" class=\"edge\">\n<title>float32_transform_1&#45;&gt;concat_features</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M958.0382,-63.8815C1001.2215,-67.8853 1066.7518,-73.961 1111.7635,-78.1343\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1111.6079,-81.6348 1121.8883,-79.073 1112.2542,-74.6647 1111.6079,-81.6348\"/>\n</g>\n<!-- numpy_permute_array -->\n<g id=\"node17\" class=\"node\">\n<title>numpy_permute_array</title>\n<g id=\"a_node17\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_permute_array.html\" xlink:title=\"numpy_permute_array = NumpyPermuteArray(axis=0, permutation_indices=[0, 1, 6, 10, 12, 2, 3, 4, 5, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1280.4894\" cy=\"-82.7696\" rx=\"42.3529\" ry=\"28.0702\"/>\n<text text-anchor=\"middle\" x=\"1280.4894\" y=\"-91.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"1280.4894\" y=\"-79.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Permute&#45;</text>\n<text text-anchor=\"middle\" x=\"1280.4894\" y=\"-67.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Array</text>\n</a>\n</g>\n</g>\n<!-- concat_features&#45;&gt;numpy_permute_array -->\n<g id=\"edge17\" class=\"edge\">\n<title>concat_features&#45;&gt;numpy_permute_array</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1202.2865,-82.7696C1210.4057,-82.7696 1219.0493,-82.7696 1227.5174,-82.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1227.7125,-86.2697 1237.7124,-82.7696 1227.7124,-79.2697 1227.7125,-86.2697\"/>\n</g>\n<!-- ta1_0 -->\n<g id=\"node18\" class=\"node\">\n<title>ta1_0</title>\n<g id=\"a_node18\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.ta1.html\" xlink:title=\"ta1_0 = TA1(fun=np.sqrt, name=&#39;sqrt&#39;, datatypes=[&#39;numeric&#39;], feat_constraints=[autoai_libs.utils.fc_methods.is_non_negative, autoai_libs.utils.fc_methods.is_not_categorical], col_names=[&#39;Year&#39;, &#39;Status&#39;, &#39;Adult Mortality&#39;, &#39;infant deaths&#39;, &#39;Alcohol&#39;, &#39;percentage e...)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1385.9158\" cy=\"-82.7696\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1385.9158\" y=\"-79.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">TA1</text>\n</a>\n</g>\n</g>\n<!-- numpy_permute_array&#45;&gt;ta1_0 -->\n<g id=\"edge18\" class=\"edge\">\n<title>numpy_permute_array&#45;&gt;ta1_0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1323.0665,-82.7696C1331.5047,-82.7696 1340.3031,-82.7696 1348.552,-82.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1348.6385,-86.2697 1358.6384,-82.7696 1348.6384,-79.2697 1348.6385,-86.2697\"/>\n</g>\n<!-- fs1_0 -->\n<g id=\"node19\" class=\"node\">\n<title>fs1_0</title>\n<g id=\"a_node19\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.fs1.html\" xlink:title=\"fs1_0 = FS1(cols_ids_must_keep=range(0, 20), additional_col_count_to_keep=20, ptype=&#39;regression&#39;)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1475.9158\" cy=\"-82.7696\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1475.9158\" y=\"-79.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">FS1</text>\n</a>\n</g>\n</g>\n<!-- ta1_0&#45;&gt;fs1_0 -->\n<g id=\"edge19\" class=\"edge\">\n<title>ta1_0&#45;&gt;fs1_0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1412.9188,-82.7696C1420.9435,-82.7696 1429.8823,-82.7696 1438.4466,-82.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1438.6209,-86.2697 1448.6208,-82.7696 1438.6208,-79.2697 1438.6209,-86.2697\"/>\n</g>\n<!-- ta1_1 -->\n<g id=\"node20\" class=\"node\">\n<title>ta1_1</title>\n<g id=\"a_node20\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.ta1.html\" xlink:title=\"ta1_1 = TA1(fun=autoai_libs.cognito.transforms.textras_methods.sigmoid, name=&#39;sigmoid&#39;, datatypes=[&#39;numeric&#39;], feat_constraints=[autoai_libs.utils.fc_methods.is_not_categorical], col_names=[&#39;Year&#39;, &#39;Status&#39;, &#39;Adult Mortality&#39;, &#39;infant deaths&#39;, &#39;Alcohol&#39;, &#39;percenta...)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1565.9158\" cy=\"-82.7696\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1565.9158\" y=\"-79.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">TA1</text>\n</a>\n</g>\n</g>\n<!-- fs1_0&#45;&gt;ta1_1 -->\n<g id=\"edge20\" class=\"edge\">\n<title>fs1_0&#45;&gt;ta1_1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1502.9188,-82.7696C1510.9435,-82.7696 1519.8823,-82.7696 1528.4466,-82.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1528.6209,-86.2697 1538.6208,-82.7696 1528.6208,-79.2697 1528.6209,-86.2697\"/>\n</g>\n<!-- fs1_1 -->\n<g id=\"node21\" class=\"node\">\n<title>fs1_1</title>\n<g id=\"a_node21\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.fs1.html\" xlink:title=\"fs1_1 = FS1(cols_ids_must_keep=range(0, 20), additional_col_count_to_keep=20, ptype=&#39;regression&#39;)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1655.9158\" cy=\"-82.7696\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1655.9158\" y=\"-79.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">FS1</text>\n</a>\n</g>\n</g>\n<!-- ta1_1&#45;&gt;fs1_1 -->\n<g id=\"edge21\" class=\"edge\">\n<title>ta1_1&#45;&gt;fs1_1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1592.9188,-82.7696C1600.9435,-82.7696 1609.8823,-82.7696 1618.4466,-82.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1618.6209,-86.2697 1628.6208,-82.7696 1618.6208,-79.2697 1618.6209,-86.2697\"/>\n</g>\n<!-- extra_trees_regressor -->\n<g id=\"node22\" class=\"node\">\n<title>extra_trees_regressor</title>\n<g id=\"a_node22\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.sklearn.extra_trees_regressor.html\" xlink:title=\"extra_trees_regressor = ExtraTreesRegressor(bootstrap=True, n_jobs=2, oob_score=True, random_state=33)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1764.1706\" cy=\"-82.7696\" rx=\"45.011\" ry=\"28.0702\"/>\n<text text-anchor=\"middle\" x=\"1764.1706\" y=\"-91.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Extra&#45;</text>\n<text text-anchor=\"middle\" x=\"1764.1706\" y=\"-79.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Trees&#45;</text>\n<text text-anchor=\"middle\" x=\"1764.1706\" y=\"-67.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Regressor</text>\n</a>\n</g>\n</g>\n<!-- fs1_1&#45;&gt;extra_trees_regressor -->\n<g id=\"edge22\" class=\"edge\">\n<title>fs1_1&#45;&gt;extra_trees_regressor</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1682.9538,-82.7696C1690.7801,-82.7696 1699.6243,-82.7696 1708.5234,-82.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1708.5428,-86.2697 1718.5427,-82.7696 1708.5427,-79.2697 1708.5428,-86.2697\"/>\n</g>\n</g>\n</svg>\n"}, "metadata": {}}]}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"train_holdout_read\"></a>\n### Read training and holdout data\n\nRetrieve training dataset from AutoAI experiment as pandas DataFrame."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "training_df, holdout_df = optimizer.get_data_connections()[0].read(with_holdout_split=True)\n\ntrain_X = training_df.drop([experiment_metadata['prediction_column']], axis=1).values\ntrain_y = training_df[experiment_metadata['prediction_column']].values\n\ntest_X = holdout_df.drop([experiment_metadata['prediction_column']], axis=1).values\ny_true = holdout_df[experiment_metadata['prediction_column']].values", "execution_count": 9, "outputs": []}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"test_model\"></a>\n### Test pipeline model locally\n**Note**: you can chose the metric to evaluate the model by your own, this example contains only a basic scenario."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "from sklearn.metrics import r2_score\n\npredictions = pipeline_model.predict(test_X)\nscore = r2_score(y_true=y_true, y_pred=predictions)\nprint('r2_score: ', score)", "execution_count": 10, "outputs": [{"output_type": "error", "ename": "ValueError", "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)", "\u001b[0;32m<ipython-input-10-afb8e4ee449d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r2_score: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \"\"\"\n\u001b[1;32m    533\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 534\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    535\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \"\"\"\n\u001b[1;32m     75\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 573\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."]}]}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"refinery\"></a>\n## Pipeline refinery and testing (optional)\n\nIn this section you will learn how to refine and retrain the best pipeline returned by AutoAI.\nIt can be performed by:\n - modifying pipeline definition source code\n - using [lale](https://lale.readthedocs.io/en/latest/) library for semi-automated data science\n\n**Note**: In order to run this section change following cells to 'code' cell."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"pipeline_definition\"></a>\n### Pipeline definition source code\nFollowing cell lets you experiment with pipeline definition in python, e.g. change steps parameters.\n\nIt will inject pipeline definition to the next cell."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "raw", "source": "pipeline_model.pretty_print(combinators=False, ipython_display='input')"}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"lale_library\"></a>\n### Lale library\n\n**Note**: This is only an exemplary usage of lale package. You can import more different estimators to refine downloaded pipeline model."}, {"metadata": {}, "cell_type": "markdown", "source": "#### Import estimators"}, {"metadata": {"pycharm": {"is_executing": false, "name": "#%%\n"}}, "cell_type": "raw", "source": "from sklearn.linear_model import LinearRegression as E1\nfrom sklearn.tree import DecisionTreeRegressor as E2\nfrom sklearn.neighbors import KNeighborsRegressor as E3\nfrom lale.lib.lale import Hyperopt\nfrom lale.operators import TrainedPipeline\nfrom lale import wrap_imported_operators\nfrom lale.helpers import import_from_sklearn_pipeline\nwrap_imported_operators()"}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"decomposition_definition\"></a>\n#### Pipeline decomposition and new definition\nIn this step the last stage from pipeline is removed."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "raw", "source": "prefix = pipeline_model.remove_last().freeze_trainable()\nprefix.visualize()"}, {"metadata": {"pycharm": {"is_executing": false, "name": "#%%\n"}}, "cell_type": "raw", "source": "new_pipeline = prefix >> (E1 | E2 | E3)\nnew_pipeline.visualize()"}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"new_optimizer\"></a>\n#### New optimizer `hyperopt` configuration and training\n\nThis section can introduce other results than the original one and it should be used\nby more advanced users.\n\nNew pipeline is re-trained by passing train data to it and calling `fit` method."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "raw", "source": "hyperopt = Hyperopt(estimator=new_pipeline, cv=3, max_evals=20, scoring='r2')\nfitted_hyperopt = hyperopt.fit(train_X, train_y)"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "raw", "source": "hyperopt_pipeline = fitted_hyperopt.get_pipeline()\nnew_pipeline = hyperopt_pipeline.export_to_sklearn_pipeline()"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "raw", "source": "predictions = new_pipeline.predict(train_X)"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "raw", "source": "predictions = new_pipeline.predict(test_X)\nrefined_score = r2_score(y_true=y_true, y_pred=predictions)\nprint('r2_score: ', score)\nprint('refined_r2_score: ', refined_score)"}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"scoring\"></a>\n## Deploy and Score\n\nIn this section you will learn how to deploy and score pipeline model as webservice using WML instance."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"wml_credentials\"></a>\n### Connect to WML client in order to create deployment\n**Action:** Next you will need credentials for Watson Machine Learning and training run_id:\n - go to [Cloud catalog resources list](https://cloud.ibm.com/resources)\n - click on Services and chose Machine Learning service. Once you are there\n - click the **Service Credentials** link on the left side of the screen\n - click to expand specific credentials name.\n - copy and paste your WML credentials into the cell below\n\n*Take in mind that WML Service instance should be the same as used to generate this notebook.*"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "wml_credentials = {\n  \"apikey\": \"\",\n  \"iam_apikey_description\": \"\",\n  \"iam_apikey_name\": \"\",\n  \"iam_role_crn\": \"r\",\n  \"iam_serviceid_crn\": \"\",\n  \"instance_id\": \"\",\n  \"url\": \"\"\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"deployment\"></a>\n### Create deployment\n\n**Action**: If you want to deploy refined pipeline please change the `pipeline_model` to `new_pipeline`.\n \nIf you prefer you can also change the `deployment_name`."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "from watson_machine_learning_client.deployment import WebService\n\nservice = WebService(wml_credentials)\n\nservice.create(\n    model=pipeline_model,\n    metadata=experiment_metadata,\n    deployment_name=f'{pipeline_name}_webservice'\n)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Deployment object could be printed to show basic information:"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "print(service)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "To be able to show all available information about deployment use `.get_params()` method:"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "service.get_params()", "execution_count": null, "outputs": []}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"online_scoring\"></a>\n### Score webservice\nYou can make scoring request by calling `score()` on deployed pipeline."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "predictions = service.score(payload=holdout_df.drop([experiment_metadata['prediction_column']], axis=1).iloc[:10])\npredictions", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "If you want to work with the webservice in external Python application you can retrieve the service object by:\n - initialize service by `service = WebService(wml_credentials)`\n - get deployment_id by `service.list()` method\n - get webservice object by `service.get('deployment_id')` method\n\nAfter that you can call `service.score()` method."}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"delete_deployment\"></a>\n### Delete deployment\n\nYou can delete an existing deployment by calling `service.delete()`."}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"authors\"></a>\n### Authors\n\nLicensed Materials - Copyright \u00a9 2020 IBM. This notebook and its source code are released under the terms of the ILAN License.\nUse, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs  \n(or equivalent) and License Information document for Watson Studio Auto-generated Notebook (License Terms),  \nsuch agreements located in the link below. Specifically, the Source Components and Sample Materials clause  \nincluded in the License Information document for Watson Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"http://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BHU2B7&title=IBM%20Watson%20Studio%20Auto-generated%20Notebook%20V2.1\">License Terms</a>  \n\n___"}, {"metadata": {}, "cell_type": "code", "source": "!pip install watson-machine-learning-client", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "wml_credentials={\n    \"apikey\": \"UMJPO-NiB3EjETz-_pu0Q5SzaSni0YE1aZVcEP28EQyZ\",\n  \"instance_id\": \"c7fa8e4b-64e1-49bc-9b93-cb885bbe6fce\",\n  \"url\": \"https://eu-gb.ml.cloud.ibm.com\"\n}", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "client = ( wml_credentials )", "execution_count": 12, "outputs": [{"output_type": "error", "ename": "NameError", "evalue": "name 'WatsonMachineLearningAPIClient' is not defined", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m<ipython-input-12-d05da2e7e76f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWatsonMachineLearningAPIClient\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mwml_credentials\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;31mNameError\u001b[0m: name 'WatsonMachineLearningAPIClient' is not defined"]}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}